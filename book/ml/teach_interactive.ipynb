{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c5622-273f-4521-b841-227e1bd650d3",
   "metadata": {
    "tags": [
     "remove-input",
     "disable-download-page",
     "auto-execute-page"
    ]
   },
   "outputs": [],
   "source": [
    "# NECESSARY CELL TO REMOVE THE DOWNLOAD AND EXECUTE BUTTONS FROM THE PAGE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cc0211-9177-4a1f-8d1f-ed2b0ffee164",
   "metadata": {},
   "source": [
    "# Interactive kNN models\n",
    "\n",
    "This notebook contains three interactive exercises for understanding kNN models, underfitting and overfitting. Click {fa}`rocket` --> {guilabel}`Live Code` in the top right corner to activate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7a9dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "thebe-remove-input-init",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# pip install packages that are not in Pyodide\n",
    "%pip install ipympl==0.9.3\n",
    "%pip install seaborn==0.12.2\n",
    "\n",
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from mude_tools import magicplotter\n",
    "from cycler import cycler\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "# Set the color scheme\n",
    "sns.set_theme()\n",
    "colors = [\n",
    "    \"#0076C2\",\n",
    "    \"#EC6842\",\n",
    "    \"#A50034\",\n",
    "    \"#009B77\",\n",
    "    \"#FFB81C\",\n",
    "    \"#E03C31\",\n",
    "    \"#6CC24A\",\n",
    "    \"#EF60A3\",\n",
    "    \"#0C2340\",\n",
    "    \"#00B8C8\",\n",
    "    \"#6F1D77\",\n",
    "]\n",
    "plt.rcParams[\"axes.prop_cycle\"] = cycler(color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b15afa",
   "metadata": {
    "tags": [
     "thebe-remove-input-init",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# The true function relating t to x\n",
    "def f_truth(x, freq=1, **kwargs):\n",
    "    # Return a sine with a frequency of freq\n",
    "    return np.sin(x * freq) + x\n",
    "    # return 3. * np.exp(x) / (np.exp(x)+1)\n",
    "\n",
    "\n",
    "# The data generation function\n",
    "def f_data(epsilon=0.7, N=100, **kwargs):\n",
    "    # Apply a seed if one is given\n",
    "    if \"seed\" in kwargs:\n",
    "        np.random.seed(kwargs[\"seed\"])\n",
    "\n",
    "    # Get the minimum and maximum\n",
    "    xmin = kwargs.get(\"xmin\", 0)\n",
    "    xmax = kwargs.get(\"xmax\", 2 * np.pi)\n",
    "\n",
    "    # Generate N evenly spaced observation locations\n",
    "    x = np.linspace(xmin, xmax, N)\n",
    "\n",
    "    # Generate N noisy observations (1 at each location)\n",
    "    t = f_truth(x, **kwargs) + np.random.normal(0, epsilon, N)\n",
    "\n",
    "    # Return both the locations and the observations\n",
    "    return x, t\n",
    "\n",
    "\n",
    "# Get the observed data\n",
    "x, t = f_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e21ad",
   "metadata": {
    "tags": [
     "thebe-remove-input-init",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Define the prediction locations\n",
    "# (note that these are different from the locations where we observed our data)\n",
    "x_pred = np.linspace(0, 2 * np.pi, 1000)\n",
    "\n",
    "\n",
    "# Define a function that makes a KNN prediction at the given locations, based on the given (x,t) data\n",
    "def KNN(x, t, x_pred, k=1, **kwargs):\n",
    "    # Convert x and x_pred to a column vector in order for KNeighborsRegresser to work\n",
    "    X = x.reshape(-1, 1)\n",
    "    X_pred = x_pred.reshape(-1, 1)\n",
    "\n",
    "    # Train the KNN based on the given (x,t) data\n",
    "    neigh = KNeighborsRegressor(k)\n",
    "    neigh.fit(X, t)\n",
    "\n",
    "    # Make a prediction at the locations given by x_pred\n",
    "    y = neigh.predict(X_pred)\n",
    "\n",
    "    # Check if the regressor itself should be returned\n",
    "    if kwargs.get(\"return_regressor\", False):\n",
    "        # If so, return the fitted KNN regressor\n",
    "        return neigh\n",
    "\n",
    "    else:\n",
    "        # If not, return the predicted values\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a8fbe-3060-4c00-aec1-640623905e09",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "thebe-remove-input-init",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def get_plot1():\n",
    "    plot1 = magicplotter(f_data, f_truth, KNN, x_pred, freq=2.0, epsilon=1.0)\n",
    "    plot1.fig.canvas.toolbar_visible = False\n",
    "    plot1.add_slider(\"k\", valmin=1, valmax=50, valinit=50)\n",
    "    plot1.add_slider(\"N\", valmin=1, valmax=100, valinit=70)\n",
    "    plot1.ax.lines[0].remove()\n",
    "    plot1.show()\n",
    "    return plot1\n",
    "\n",
    "\n",
    "def get_plot2():\n",
    "    plot2 = magicplotter(f_data, f_truth, KNN, x_pred, freq=2.0, epsilon=1.0)\n",
    "    plot2.fig.canvas.toolbar_visible = False\n",
    "    plot2.add_slider(\"k\", valmin=1, valmax=50, valinit=1)\n",
    "    plot2.show()\n",
    "    return plot2\n",
    "\n",
    "\n",
    "def get_plot3():\n",
    "    plot3 = magicplotter(f_data, f_truth, KNN, x_pred, freq=2.0, epsilon=1.0)\n",
    "    plot3.fig.canvas.toolbar_visible = False\n",
    "    plot3.add_slider(\"k\", valmin=1, valmax=50, valinit=1)\n",
    "    plot3.add_sidebar()\n",
    "    plot3.ax_mse.set_ylim((-0.05, 2.0))\n",
    "    plot3.ax.lines[0].remove()\n",
    "    plot3.show()\n",
    "    return plot3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346df44",
   "metadata": {},
   "source": [
    "## Training a first model\n",
    "\n",
    "Play with the interactive model below and try to build the best possible model given our $N$ data points. Remember we are trying to minimize the error when making predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73052e21",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "plot1 = get_plot1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47913e7-2b2f-4bba-bd32-4b8838856afd",
   "metadata": {},
   "source": [
    "## Training a model while knowing the ground truth\n",
    "\n",
    "We repeat the exercise from before but now including the exact function we are trying to approximate (ground truth). Try it out below. Did your choice of $k$ change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b967d-0ec4-4d16-9f4a-9a17f190cd4a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot2 = get_plot2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e09ee-7033-4c93-82a1-ec28643191f3",
   "metadata": {},
   "source": [
    "## Training a good model under limited knowledge\n",
    "\n",
    "Of course, in practice the ground truth is unknown! We only have our data to work with, and nothing else. Below we are using 80% of our dataset for training and 20% for validation. Try to build a model with as low validation error as possible. Then compare with the two models you trained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202df505-93f3-44be-849d-e1682b7f9a1f",
   "metadata": {
    "tags": [
     "full-width"
    ]
   },
   "outputs": [],
   "source": [
    "plot3 = get_plot3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03119e4",
   "metadata": {},
   "source": [
    "% START-CREDIT\n",
    "% source: machine_learning\n",
    "```{attributiongrey} Attribution\n",
    ":class: attribution\n",
    "This chapter is written by Iuri Rocha, Anne Poot, Joep Storm and Leon Riccius. {ref}`Find out more here <machine_learning_credit>`.\n",
    "```\n",
    "% END-CREDIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
